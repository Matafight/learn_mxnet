{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:letter-recognition.data exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "fname = mx.test_utils.download('http://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data')\n",
    "data = np.genfromtxt(fname, delimiter=',')[:,1:]\n",
    "label = np.array([ord(l.split(',')[0])-ord('A') for l in open(fname, 'r')])\n",
    "\n",
    "batch_size = 32\n",
    "ntrain = int(data.shape[0]*0.8)\n",
    "train_iter = mx.io.NDArrayIter(data[:ntrain, :], label[:ntrain], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(data[ntrain:, :], label[ntrain:], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from gen_input import gen_input\n",
    "##这个数据还不太好使，我换别的数据试试\n",
    "#data_iter = gen_input()\n",
    "#data_iter.reset()\n",
    "#data = data_iter.next()\n",
    "#data_features = data.data[0]\n",
    "#data_label=data.label[0]\n",
    "#train_iter = mx.io.NDArrayIter(data_features,data_label,batch_size=6,shuffle=True)\n",
    "#valid_iter = train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = mx.sym.Variable('data')\n",
    "net = mx.sym.FullyConnected(net, name='fc1', num_hidden=64)\n",
    "net = mx.sym.Activation(net, name='relu1', act_type=\"relu\")\n",
    "net = mx.sym.FullyConnected(net, name='fc2', num_hidden=26)\n",
    "#net = mx.sym.FullyConnected(net, name='fc3', num_hidden=2)\n",
    "net = mx.sym.SoftmaxOutput(net, name='softmax')\n",
    "#mx.viz.plot_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(symbol=net,\n",
    "                    context=mx.cpu(),\n",
    "                    data_names=['data'],\n",
    "                    label_names=['softmax_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training ('accuracy', 0.44274999999999998)\n",
      "Epoch 1, Training ('accuracy', 0.65031249999999996)\n",
      "Epoch 2, Training ('accuracy', 0.70787500000000003)\n",
      "Epoch 3, Training ('accuracy', 0.74306249999999996)\n",
      "Epoch 4, Training ('accuracy', 0.76231249999999995)\n"
     ]
    }
   ],
   "source": [
    "# allocate memory given the input data and label shapes\n",
    "mod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "# initialize parameters by uniform random numbers\n",
    "mod.init_params(initializer=mx.init.Uniform(scale=.1))\n",
    "# use SGD with learning rate 0.1 to train\n",
    "mod.init_optimizer(optimizer='sgd', optimizer_params=(('learning_rate', 0.1), ))\n",
    "# use accuracy as the metric\n",
    "metric = mx.metric.create('acc')\n",
    "# train 5 epochs, i.e. going over the data iter one pass\n",
    "for epoch in range(5):\n",
    "    train_iter.reset()\n",
    "    metric.reset()\n",
    "    for batch in train_iter:\n",
    "        mod.forward(batch, is_train=True)       # compute predictions\n",
    "        mod.update_metric(metric, batch.label)  # accumulate prediction accuracy\n",
    "        mod.backward()                          # compute gradients\n",
    "        mod.update()                            # update parameters\n",
    "    print('Epoch %d, Training %s' % (epoch, metric.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataDesc[data,(32, 16),<class 'numpy.float32'>,NCHW]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter.provide_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('softmax_label', \n",
       "  [  2.   3.   1. ...,  14.  25.   5.]\n",
       "  <NDArray 16000 @cpu(0)>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
