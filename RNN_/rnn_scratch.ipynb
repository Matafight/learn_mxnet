{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64925\n"
     ]
    }
   ],
   "source": [
    "with open('./input/jaychou_lyrics.txt','r',encoding='utf-8') as fh:\n",
    "    lines = fh.read()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = lines.replace('\\n', ' ').replace('\\r', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每天在想想想想著你 这样的甜蜜 让我开始乡相信命运 感谢地心引力 让我碰到你 漂亮的让我面红的可爱女人 温柔的让我心疼的可'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct data iterator \n",
    "content = content[0:20000]\n",
    "idx_to_char = list(set(content))\n",
    "char_to_idx = dict([(char,int(i)) for i,char in enumerate(idx_to_char)])\n",
    "vocab_size = len(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_corpus = [char_to_idx[c] for c in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每\n"
     ]
    }
   ],
   "source": [
    "s = ''.join([idx_to_char[i] for i in idx_corpus])\n",
    "print(s[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import mxnet as mx\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from util import update\n",
    "\n",
    "def data_iter_random(num_steps,batch_size,corpus,ctx=mx.cpu()):\n",
    "    #随机生成 data iterator，用yield返回？？\n",
    "    #先随机分段\n",
    "    #再随机选择batch_size个字段\n",
    "    len_corpus=len(corpus)\n",
    "    num_patch = len_corpus//num_steps\n",
    "    num_batch = num_patch//batch_size \n",
    "    idx_list = [x for x in range(num_patch)]\n",
    "    random.shuffle(idx_list)\n",
    "    \n",
    "    for batch in range(num_batch):\n",
    "        #在idx_list中随机选择batch_size 个元素，选完之后在idx_list中删除这些元素\n",
    "        to_use = random.sample(idx_list,batch_size)\n",
    "        batch_data = []\n",
    "        batch_label = []\n",
    "        for item in to_use:\n",
    "            idx_list.remove(item)\n",
    "        for step in to_use:\n",
    "            #i * num_patch ~ (i+1)*num_path\n",
    "            data = corpus[step*num_steps:(step+1)*num_steps]\n",
    "            batch_data.append(data)\n",
    "            #判断最后一个是否越界\n",
    "            if (step+1)*num_steps < len_corpus:\n",
    "                label = corpus[step*num_steps + 1:(step+1)*num_steps+1]\n",
    "            else:\n",
    "                label = corpus[step*num_steps+1:(step+1)*num_steps]\n",
    "                label.append('0')#填充字符\n",
    "            batch_label.append(label)\n",
    "        #聚合\n",
    "        #ndarray batch_size * num_steps\n",
    "        batch_data = mx.ndarray.array(batch_data)\n",
    "        batch_label = mx.ndarray.array(batch_label)\n",
    "        yield(batch_data,batch_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data_iter = data_iter_random(3,10,idx_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_iter_consective(num_steps,batch_size,corpus,ctx=mx.cpu()):\n",
    "    #连续采样\n",
    "    num_patch = len(corpus)//num_steps\n",
    "    num_batch = num_patch//batch_size\n",
    "    \n",
    "    \n",
    "    for i_batch in range(num_batch):\n",
    "        total_data = []\n",
    "        total_label = []\n",
    "        for i_batch_size in range(batch_size):\n",
    "            start_pos = i_batch+num_batch*(i_batch_size)\n",
    "            data = corpus[start_pos*num_steps:(start_pos+1)*num_steps]\n",
    "            #判断最后是否越界\n",
    "            if(start_pos+1)*num_steps < len(corpus):\n",
    "                label = corpus[start_pos*num_steps+1:(start_pos+1)*num_steps+1]\n",
    "            else:\n",
    "                label = corpus[start_pos*num_steps+1:(start_pos+1)*num_steps]\n",
    "                label.append('0')\n",
    "            total_data.append(data)\n",
    "            total_label.append(label)\n",
    "        total_data = mx.ndarray.array(total_data)\n",
    "        total_label = mx.ndarray.array(total_label)\n",
    "        yield(total_data,total_label)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#验证 iter是否正确\n",
    "def valid_data_iter():\n",
    "    corpus = list(range(10000))\n",
    "    batch_size = 10\n",
    "    num_steps = 3\n",
    "    data_iter_rand = data_iter_consective(batch_size=batch_size,num_steps=num_steps,corpus=corpus)\n",
    "    count = 0\n",
    "    for item in data_iter_rand:\n",
    "        if(count>10):\n",
    "            break;\n",
    "        count +=1\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据还需要编码，采用最简单的one-hot-encoding 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet.ndarray as nd\n",
    "for data,label in data_iter_consective(3,10,idx_corpus):\n",
    "    inp =[nd.one_hot(x,vocab_size) for x in data.T]\n",
    "    break\n",
    "    \n",
    "def one_hot(data,vocab_size):\n",
    "    inp = [nd.one_hot(x,vocab_size) for x in data.T]\n",
    "    #len(inp) = num_steps\n",
    "    return inp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#尝试使用gpu\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import util\n",
    "ctx=util.try_gpu()\n",
    "\n",
    "#construct rnn\n",
    "hidden_dim = 256\n",
    "output_dim = vocab_size\n",
    "input_dim = vocab_size\n",
    "batch_size  = 32\n",
    "std = .01\n",
    "learning_rate = 0.2\n",
    "def get_params():\n",
    "    #set params\n",
    "    W_xh= nd.random_normal(scale=std,shape=(input_dim,hidden_dim),ctx=ctx)\n",
    "    W_hh = nd.random_normal(scale=std,shape=(hidden_dim,hidden_dim),ctx=ctx)\n",
    "    b_h = nd.zeros(hidden_dim,ctx=ctx)\n",
    "    \n",
    "    W_hy = nd.random_normal(scale = std,shape=(hidden_dim,output_dim),ctx=ctx)\n",
    "    b_y = nd.zeros(output_dim,ctx=ctx)\n",
    "    params = [W_xh,W_hh,b_h,W_hy,b_y]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output len:3\n",
      "output[0] shape (32, 1465)\n"
     ]
    }
   ],
   "source": [
    "def rnn(inputs,states,*params):\n",
    "    #inputs  is a list shape = batch_size * input_dim\n",
    "    H = states\n",
    "    W_xh,W_hh,b_h,W_hy,b_y = params\n",
    "    outputs = [] \n",
    "    for X in inputs:\n",
    "        H = nd.tanh(nd.dot(X,W_xh)+nd.dot(H,W_hh)+b_h)\n",
    "        Y = nd.dot(H,W_hy)+b_y\n",
    "        outputs.append(Y)\n",
    "    return (outputs,H)\n",
    "        \n",
    "#test\n",
    "params = get_params()\n",
    "states = nd.zeros((batch_size,hidden_dim),ctx=ctx)\n",
    "inputs = [nd.ones((batch_size,input_dim),ctx=ctx)] *3\n",
    "(outputs,H) = rnn(inputs,states,*params)\n",
    "print('output len:%d'%len(outputs))\n",
    "print('output[0] shape',outputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training and inference\n",
    "\n",
    "def predict_rnn(rnn,prefix,vocab_size,num_char,params,hidden_dim,char_to_idx,idx_to_char):\n",
    "    H = nd.zeros(shape=(1,hidden_dim),ctx=ctx)\n",
    "    outputs = []\n",
    "    outputs.append(char_to_idx[prefix[0]])\n",
    "    \n",
    "    for i in range(num_char+len(prefix)):\n",
    "        x = nd.array([outputs[-1]],ctx=ctx)\n",
    "        x = one_hot(x,vocab_size)\n",
    "        out, H = rnn(x,H,*params)\n",
    "        if i< len(prefix)-1:\n",
    "            new_input = char_to_idx[prefix[i+1]]\n",
    "        else:\n",
    "            new_input  = int(out[-1].argmax(axis=1).asscalar())\n",
    "        outputs.append(new_input)\n",
    "    return ''.join([idx_to_char[x] for x in outputs])\n",
    "    \n",
    "#prefix='书由 nainia'\n",
    "#predict_rnn(rnn,prefix,vocab_size,10,params,hidden_dim,char_to_idx,idx_to_char)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gradient cliping\n",
    "def grad_clipping(params,theta):\n",
    "    #python传参是传的引用，所有不用返回值\n",
    "    norm = nd.array([0.0],ctx=ctx)\n",
    "    for p in params:\n",
    "        norm = norm + nd.sum(p.grad**2)\n",
    "    norm = nd.sqrt(norm).asscalar()\n",
    "    if norm > theta:\n",
    "        for p in params:\n",
    "            p.grad[:] =p.grad[:]* theta/norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    "#perplexity 困惑度\n",
    "import numpy as np\n",
    "def train_and_predict(num_steps):\n",
    "    #how?\n",
    "    #定义损失\n",
    "    seq1 = '分开'\n",
    "    seq2 = '不分开'\n",
    "    seq3 = '战争中部队'\n",
    "    seqs = [seq1, seq2, seq3]\n",
    "    loss = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    #生成数据迭代器\n",
    "    #循环num_epoch\n",
    "    num_epochs = 200\n",
    "    \n",
    "    params = get_params()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        data_iter = data_iter_random(num_steps,batch_size,idx_corpus)\n",
    "        num_example = 0.0\n",
    "        for data,label in data_iter:\n",
    "            data = one_hot(nd.array(data,ctx=ctx),vocab_size)\n",
    "            H = nd.zeros(shape=(batch_size,hidden_dim),ctx=ctx)\n",
    "            label = nd.array(label,ctx=ctx)\n",
    "            with mx.autograd.record():\n",
    "                outputs,H = rnn(data,H,*params)\n",
    "                #计算loss\n",
    "                #for i in range(len(out)):\n",
    "                #    myloss = loss(out[i],label[:,i])\n",
    "                #    train_loss += nd.sum(myloss).asscalar()\n",
    "                label = label.T.reshape((-1,))\n",
    "                outputs = nd.concat(*outputs, dim=0)\n",
    "                myloss=loss(outputs,label)\n",
    "            myloss.backward()\n",
    "            grad_clipping(params,5)\n",
    "            update(params,learning_rate)\n",
    "            train_loss += nd.sum(myloss).asscalar()\n",
    "            num_example += myloss.size\n",
    "        print('Epoch:%d  Perplexity:%f'%(epoch,np.exp(train_loss/num_example)))\n",
    "        if epoch % 10 ==0:\n",
    "            #predict_rnn\n",
    "            for seq in seqs:\n",
    "                print(predict_rnn(rnn,seq,vocab_size,10,params,hidden_dim,char_to_idx,idx_to_char))\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0  Perplexity:892.700149\n",
      "分开           \n",
      "不分开           \n",
      "战争中部队           \n",
      "Epoch:1  Perplexity:483.236306\n",
      "Epoch:2  Perplexity:428.574377\n",
      "Epoch:3  Perplexity:410.862956\n",
      "Epoch:4  Perplexity:390.061948\n",
      "Epoch:5  Perplexity:378.325043\n",
      "Epoch:6  Perplexity:363.259748\n",
      "Epoch:7  Perplexity:356.755914\n",
      "Epoch:8  Perplexity:337.454115\n",
      "Epoch:9  Perplexity:328.284121\n",
      "Epoch:10  Perplexity:311.815427\n",
      "分开 我 我 我 我 我 \n",
      "不分开 我 我 我 我 我 \n",
      "战争中部队 我 我 我 我 我 \n",
      "Epoch:11  Perplexity:299.550010\n",
      "Epoch:12  Perplexity:290.568963\n",
      "Epoch:13  Perplexity:278.737281\n",
      "Epoch:14  Perplexity:264.593851\n",
      "Epoch:15  Perplexity:256.465755\n",
      "Epoch:16  Perplexity:246.065591\n",
      "Epoch:17  Perplexity:239.134919\n",
      "Epoch:18  Perplexity:228.973926\n",
      "Epoch:19  Perplexity:218.598968\n",
      "Epoch:20  Perplexity:208.192696\n",
      "分开 你不的让我不 你想的\n",
      "不分开 你不的让我不 你想的\n",
      "战争中部队 你不的让我不 你想的\n",
      "Epoch:21  Perplexity:200.446446\n",
      "Epoch:22  Perplexity:190.808660\n",
      "Epoch:23  Perplexity:183.945792\n",
      "Epoch:24  Perplexity:171.890856\n",
      "Epoch:25  Perplexity:165.144290\n",
      "Epoch:26  Perplexity:157.784655\n",
      "Epoch:27  Perplexity:149.192357\n",
      "Epoch:28  Perplexity:144.662812\n",
      "Epoch:29  Perplexity:138.413025\n",
      "Epoch:30  Perplexity:129.586425\n",
      "分开 我想要你想 我不要我\n",
      "不分开 我想要你的爱我 我不\n",
      "战争中部队 我想要你的爱我 我不\n",
      "Epoch:31  Perplexity:125.908308\n",
      "Epoch:32  Perplexity:117.609711\n",
      "Epoch:33  Perplexity:112.872442\n",
      "Epoch:34  Perplexity:107.531411\n",
      "Epoch:35  Perplexity:102.734484\n",
      "Epoch:36  Perplexity:97.784405\n",
      "Epoch:37  Perplexity:92.848453\n",
      "Epoch:38  Perplexity:88.535817\n",
      "Epoch:39  Perplexity:84.265305\n",
      "Epoch:40  Perplexity:81.450748\n",
      "分开 你不是我不要我 你我\n",
      "不分开你 我不要你的爱我 你\n",
      "战争中部队 (不的手不是我的可爱\n",
      "Epoch:41  Perplexity:75.475213\n",
      "Epoch:42  Perplexity:72.828634\n",
      "Epoch:43  Perplexity:69.831680\n",
      "Epoch:44  Perplexity:66.066174\n",
      "Epoch:45  Perplexity:63.604700\n",
      "Epoch:46  Perplexity:60.626973\n",
      "Epoch:47  Perplexity:56.802654\n",
      "Epoch:48  Perplexity:53.155264\n",
      "Epoch:49  Perplexity:51.765773\n",
      "Epoch:50  Perplexity:49.307654\n",
      "分开 我不要再想你 我知不\n",
      "不分开 我给我这多你是我 不\n",
      "战争中部队的可爱 我不能你想 我\n",
      "Epoch:51  Perplexity:46.331200\n",
      "Epoch:52  Perplexity:43.988750\n",
      "Epoch:53  Perplexity:42.571937\n",
      "Epoch:54  Perplexity:40.198827\n",
      "Epoch:55  Perplexity:37.924203\n",
      "Epoch:56  Perplexity:36.446770\n",
      "Epoch:57  Perplexity:35.203011\n",
      "Epoch:58  Perplexity:33.464875\n",
      "Epoch:59  Perplexity:31.733999\n",
      "Epoch:60  Perplexity:29.754949\n",
      "分开 我不想再想你 我说不\n",
      "不分开 我给不这样你 你说着\n",
      "战争中部队 看不泡 一颗两步三颗\n",
      "Epoch:61  Perplexity:28.576748\n",
      "Epoch:62  Perplexity:27.549497\n",
      "Epoch:63  Perplexity:26.281903\n",
      "Epoch:64  Perplexity:25.075566\n",
      "Epoch:65  Perplexity:23.783810\n",
      "Epoch:66  Perplexity:23.332290\n",
      "Epoch:67  Perplexity:22.184615\n",
      "Epoch:68  Perplexity:21.374234\n",
      "Epoch:69  Perplexity:20.593024\n",
      "Epoch:70  Perplexity:19.750321\n",
      "分开 我不想再想你 我知不\n",
      "不分开 我给不这样 我的完美\n",
      "战争中部队家 我的回界主能 我不\n",
      "Epoch:71  Perplexity:18.414610\n",
      "Epoch:72  Perplexity:18.315891\n",
      "Epoch:73  Perplexity:17.529503\n",
      "Epoch:74  Perplexity:16.749681\n",
      "Epoch:75  Perplexity:16.138685\n",
      "Epoch:76  Perplexity:15.570800\n",
      "Epoch:77  Perplexity:14.779371\n",
      "Epoch:78  Perplexity:14.021679\n",
      "Epoch:79  Perplexity:13.954111\n",
      "Epoch:80  Perplexity:13.459265\n",
      "分开 你爱经 一步两 三颗\n",
      "不分开 我想不再球你的世 别\n",
      "战争中部队一张一定想能想 我想 \n",
      "Epoch:81  Perplexity:12.645800\n",
      "Epoch:82  Perplexity:12.473031\n",
      "Epoch:83  Perplexity:12.032322\n",
      "Epoch:84  Perplexity:11.759203\n",
      "Epoch:85  Perplexity:11.259396\n",
      "Epoch:86  Perplexity:10.901872\n",
      "Epoch:87  Perplexity:10.741191\n",
      "Epoch:88  Perplexity:10.219689\n",
      "Epoch:89  Perplexity:9.931294\n",
      "Epoch:90  Perplexity:9.629549\n",
      "分开 你是我看多难 我知着\n",
      "不分开 现在这经看不到 铁盒\n",
      "战争中部队老 塞着的客栈人多 牧\n",
      "Epoch:91  Perplexity:9.502358\n",
      "Epoch:92  Perplexity:9.091773\n",
      "Epoch:93  Perplexity:8.826052\n",
      "Epoch:94  Perplexity:8.557487\n",
      "Epoch:95  Perplexity:8.307692\n",
      "Epoch:96  Perplexity:7.966824\n",
      "Epoch:97  Perplexity:8.025834\n",
      "Epoch:98  Perplexity:7.742706\n",
      "Epoch:99  Perplexity:7.438367\n",
      "Epoch:100  Perplexity:7.337690\n",
      "分开 你是我真的画面 只要\n",
      "不分开 现在我有说你是 我不\n",
      "战争中部队子 也在 故阵飞 为炭\n",
      "Epoch:101  Perplexity:7.221559\n",
      "Epoch:102  Perplexity:7.121969\n",
      "Epoch:103  Perplexity:6.945158\n",
      "Epoch:104  Perplexity:6.778270\n",
      "Epoch:105  Perplexity:6.469752\n",
      "Epoch:106  Perplexity:6.365836\n",
      "Epoch:107  Perplexity:6.161108\n",
      "Epoch:108  Perplexity:6.163925\n",
      "Epoch:109  Perplexity:5.858933\n",
      "Epoch:110  Perplexity:5.722782\n",
      "分开 你是我也辈世堪 我根\n",
      "不分开 现在不是 为人的钥匙\n",
      "战争中部队过 我想你这样弃着你的\n",
      "Epoch:111  Perplexity:5.718531\n",
      "Epoch:112  Perplexity:5.601173\n",
      "Epoch:113  Perplexity:5.567685\n",
      "Epoch:114  Perplexity:5.448835\n",
      "Epoch:115  Perplexity:5.325042\n",
      "Epoch:116  Perplexity:5.223177\n",
      "Epoch:117  Perplexity:5.043518\n",
      "Epoch:118  Perplexity:5.056874\n",
      "Epoch:119  Perplexity:4.968686\n",
      "Epoch:120  Perplexity:4.789808\n",
      "分开 你是我看的太界 这样\n",
      "不分开着我嘲多 回忆逐渐燃每\n",
      "战争中部队个蔓~ 你爷泡的茶 有\n",
      "Epoch:121  Perplexity:4.753283\n",
      "Epoch:122  Perplexity:4.702739\n",
      "Epoch:123  Perplexity:4.645505\n",
      "Epoch:124  Perplexity:4.545646\n",
      "Epoch:125  Perplexity:4.461356\n",
      "Epoch:126  Perplexity:4.359097\n",
      "Epoch:127  Perplexity:4.309256\n",
      "Epoch:128  Perplexity:4.211872\n",
      "Epoch:129  Perplexity:4.198599\n",
      "Epoch:130  Perplexity:4.139573\n",
      "分开了你和上的乾 就些的神\n",
      "不分开 现在 有去 ㄙㄡ ㄈ\n",
      "战争中部队过 也许的传栈人多的喊\n",
      "Epoch:131  Perplexity:4.132735\n",
      "Epoch:132  Perplexity:4.056227\n",
      "Epoch:133  Perplexity:3.968590\n",
      "Epoch:134  Perplexity:3.941260\n",
      "Epoch:135  Perplexity:3.948186\n",
      "Epoch:136  Perplexity:3.814902\n",
      "Epoch:137  Perplexity:3.903539\n",
      "Epoch:138  Perplexity:3.734745\n",
      "Epoch:139  Perplexity:3.666506\n",
      "Epoch:140  Perplexity:3.628129\n",
      "分开 你不会梦一天 它知后\n",
      "不分开 现经 失去 ㄙ你 从\n",
      "战争中部队重 放到颓受 是谁出中\n",
      "Epoch:141  Perplexity:3.585900\n",
      "Epoch:142  Perplexity:3.507271\n",
      "Epoch:143  Perplexity:3.471450\n",
      "Epoch:144  Perplexity:3.431248\n",
      "Epoch:145  Perplexity:3.397554\n",
      "Epoch:146  Perplexity:3.375927\n",
      "Epoch:147  Perplexity:3.376872\n",
      "Epoch:148  Perplexity:3.322794\n",
      "Epoch:149  Perplexity:3.273181\n",
      "Epoch:150  Perplexity:3.212332\n",
      "分开了你不想再 你在那全快\n",
      "不分开 现在我面要)  单么\n",
      "战争中部队过去方就 你说你前的没\n",
      "Epoch:151  Perplexity:3.210389\n",
      "Epoch:152  Perplexity:3.221716\n",
      "Epoch:153  Perplexity:3.114756\n",
      "Epoch:154  Perplexity:3.166651\n",
      "Epoch:155  Perplexity:3.057418\n",
      "Epoch:156  Perplexity:3.017534\n",
      "Epoch:157  Perplexity:3.017968\n",
      "Epoch:158  Perplexity:2.959875\n",
      "Epoch:159  Perplexity:2.972045\n",
      "Epoch:160  Perplexity:3.010466\n",
      "分开了你不会 心所好　边像\n",
      "不分开 已经是经满不说 我想\n",
      "战争中部队子 它在小风我已糗 却\n",
      "Epoch:161  Perplexity:2.941009\n",
      "Epoch:162  Perplexity:2.990244\n",
      "Epoch:163  Perplexity:2.885399\n",
      "Epoch:164  Perplexity:2.920741\n",
      "Epoch:165  Perplexity:2.862217\n",
      "Epoch:166  Perplexity:2.826375\n",
      "Epoch:167  Perplexity:2.769089\n",
      "Epoch:168  Perplexity:2.798078\n",
      "Epoch:169  Perplexity:2.783681\n",
      "Epoch:170  Perplexity:2.746957\n",
      "分开了你已会 心所谓 反手\n",
      "不分开 习么 失去意义 戒指\n",
      "战争中部队暴 放上无与 是谁村子\n",
      "Epoch:171  Perplexity:2.711373\n",
      "Epoch:172  Perplexity:2.664218\n",
      "Epoch:173  Perplexity:2.712962\n",
      "Epoch:174  Perplexity:2.672331\n",
      "Epoch:175  Perplexity:2.678440\n",
      "Epoch:176  Perplexity:2.663344\n",
      "Epoch:177  Perplexity:2.629547\n",
      "Epoch:178  Perplexity:2.662821\n",
      "Epoch:179  Perplexity:2.583987\n",
      "Epoch:180  Perplexity:2.564033\n",
      "分开后你不会 想离当年边正\n",
      "不分开 现在那经看不要 铁盒\n",
      "战争中部队地南会 古小的父音那娇\n",
      "Epoch:181  Perplexity:2.545429\n",
      "Epoch:182  Perplexity:2.539522\n",
      "Epoch:183  Perplexity:2.542047\n",
      "Epoch:184  Perplexity:2.540215\n",
      "Epoch:185  Perplexity:2.540700\n",
      "Epoch:186  Perplexity:2.495329\n",
      "Epoch:187  Perplexity:2.533039\n",
      "Epoch:188  Perplexity:2.507151\n",
      "Epoch:189  Perplexity:2.457480\n",
      "Epoch:190  Perplexity:2.402945\n",
      "分开后你已会就 你已从前快\n",
      "不分开 习在那经看不要 铁盒\n",
      "战争中部队重 也着颓的字写啸像的\n",
      "Epoch:191  Perplexity:2.393044\n",
      "Epoch:192  Perplexity:2.400151\n",
      "Epoch:193  Perplexity:2.428202\n",
      "Epoch:194  Perplexity:2.397563\n",
      "Epoch:195  Perplexity:2.385931\n",
      "Epoch:196  Perplexity:2.374156\n",
      "Epoch:197  Perplexity:2.399406\n",
      "Epoch:198  Perplexity:2.365067\n",
      "Epoch:199  Perplexity:2.369610\n"
     ]
    }
   ],
   "source": [
    "num_steps=35\n",
    "train_and_predict(num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet.ndarray as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = nd.ones((10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]\n",
       " [ 1.  1.  1.]]\n",
       "<NDArray 10x3 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
       "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
       "<NDArray 30 @cpu(0)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
